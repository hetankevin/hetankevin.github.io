---
---

@article{Wheeler_2024,
   title={Informing policy via dynamic models: Cholera in Haiti},
   volume={20},
   ISSN={1553-7358},
   url={http://dx.doi.org/10.1371/journal.pcbi.1012032},
   DOI={10.1371/journal.pcbi.1012032},
   number={4},
   journal={PLOS Computational Biology},
   publisher={Public Library of Science (PLoS)},
   author={Wheeler, Jesse and Rosengart, AnnaElaine and Jiang, Zhuoxun and Tan, Kevin and Treutle, Noah and Ionides, Edward L.},
   editor={Britton, Tom},
   year={2024},
   month=apr, pages={e1012032} }


@InProceedings{pmlr-v238-kausik24a,
  title = 	 {Offline Policy Evaluation and Optimization Under Confounding},
  author =       {Kausik, Chinmaya and Lu, Yangyi and Tan, Kevin and Makar, Maggie and Wang, Yixin and Tewari, Ambuj},
  booktitle = 	 {Proceedings of The 27th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {1459--1467},
  year = 	 {2024},
  editor = 	 {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},
  volume = 	 {238},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {02--04 May},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v238/kausik24a/kausik24a.pdf},
  url = 	 {https://proceedings.mlr.press/v238/kausik24a.html},
  abstract = 	 {Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on whether they are memoryless and on their effect on the data-collection policies. We characterize settings where consistent value estimates are provably not achievable, and provide algorithms with guarantees to instead estimate lower bounds on the value. When consistent estimates are achievable, we provide algorithms for value estimation with sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on both a gridworld environment and a simulated healthcare setting of managing sepsis patients. In gridworld, our model-based method provides tighter lower bounds than existing methods, while in the sepsis simulator, we demonstrate the effectiveness of our method and investigate the importance of a clustering sub-routine.}
}


@InProceedings{pmlr-v202-kausik23a,
  title = 	 {Learning Mixtures of {M}arkov Chains and {MDP}s},
  author =       {Kausik, Chinmaya and Tan, Kevin and Tewari, Ambuj},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {15970--16017},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/kausik23a/kausik23a.pdf},
  url = 	 {https://proceedings.mlr.press/v202/kausik23a.html},
  abstract = 	 {We present an algorithm for learning mixtures of Markov chains and Markov decision processes (MDPs) from short unlabeled trajectories. Specifically, our method handles mixtures of Markov chains with optional control input by going through a multi-step process, involving (1) a subspace estimation step, (2) spectral clustering of trajectories using "pairwise distance estimators," along with refinement using the EM algorithm, (3) a model estimation step, and (4) a classification step for predicting labels of new trajectories. We provide end-to-end performance guarantees, where we only explicitly require the length of trajectories to be linear in the number of states and the number of trajectories to be linear in a mixing time parameter. Experimental results support these guarantees, where we attain 96.6% average accuracy on a mixture of two MDPs in gridworld, outperforming the EM algorithm with random initialization (73.2% average accuracy). We also significantly outperform the EM algorithm on real data from the LastFM song dataset.}
}


@inproceedings{
kausik2025leveraging,
title={Leveraging Offline Data in Linear Latent Contextual Bandits},
author={Chinmaya Kausik and Kevin Tan and Ambuj Tewari},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=jMNQaNbjQl}
}

@inproceedings{NEURIPS2024_d9251dc2,
 author = {Tan, Kevin and Fan, Wei and Wei, Yuting},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {120038--120077},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Reinforcement Learning Breaks Sample Size Barriers In Linear MDPs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/d9251dc20346dffe9b6db86dcc6f8cc9-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}


@misc{tan2024acceleratedinferencepartiallyobserved,
      title={Accelerated Inference for Partially Observed Markov Processes using Automatic Differentiation}, 
      author={Kevin Tan and Giles Hooker and Edward L. Ionides},
      year={2024},
      eprint={2407.03085},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2407.03085}, 
}

@inproceedings{NEURIPS2024_86c28392,
 author = {Garg, Sachin and Tan, Kevin and Derezi\'{n}ski, Micha\l },
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {73745--73782},
 publisher = {Curran Associates, Inc.},
 title = {Distributed Least Squares in Small Space via Sketching and Bias Reduction},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/86c283920335ed1fec3edee227e05fbf-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}


@article{tan2024natural,
    title={A Natural Extension To Online Algorithms For Hybrid {RL} With Limited Coverage},
    author={Tan, Kevin and Xu, Ziping},
    journal={Reinforcement Learning Journal},
    volume={3},
    pages={1252--1264},
    year={2024}
}

@inproceedings{
tan2025actorcritics,
title={Actor-Critics Can Achieve Optimal Sample Efficiency},
author={Kevin Tan and Wei Fan and Yuting Wei},
booktitle={Forty-second International Conference on Machine Learning},
year={2025},
url={https://openreview.net/forum?id=1laMy7jPux}
}